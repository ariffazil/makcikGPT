# THESIS.md

## Core Claim

Reliable AI operations require a governance kernel between language models and real-world actions.

## Why

An LLM is a powerful inference engine, not a sovereign decision authority. Without hard boundaries, confidence can be mistaken for legitimacy.

## Kernel Function

The kernel enforces non-negotiable transitions:

- authority gating,
- evidence grounding,
- human hold points for irreversible risk,
- and auditable decision receipts.

## Expected Effect

Even with unchanged model weights, constrained environments produce more disciplined behavior:

- fewer unsafe actions,
- earlier uncertainty disclosure,
- safer fallback paths,
- and clearer post-incident accountability.

## Non-Claims

- Not a guarantee of factual omniscience.
- Not an elimination of uncertainty.
- Not moral theater.

## Practical Position

For production systems, the target is not perfect prediction. The target is bounded failure with accountable process.
