# FAQ.md

## What is arifOS in one line?

An intelligence-governance kernel that sits between LLM output and operational execution.

## Is this a new model?

No. It is a control layer around existing models.

## What does the kernel enforce?

- Authority before execution
- Evidence before consequential claims
- Human hold (`888_HOLD`) before irreversible operations
- `VOID` when grounding fails
- Decision receipts for auditability

## Why call it an "intelligence kernel"?

Because constraints shape behavior. Under stable boundaries, the system behaves more reliably without retraining the base model.

## Does it guarantee truth?

No. It guarantees process constraints and accountability, not omniscience.

## Why not rely on prompt instructions only?

Prompts are requests. Kernels are boundaries. Operational safety needs enforceable boundaries.

## Is this anti-autonomy?

No. It is pro-safe autonomy: reversible defaults, explicit escalation, and human ratification where risk is high.

## Who is this for?

Teams connecting AI to infrastructure, code, data, and workflows where mistakes have real cost.

## What does success look like?

- fewer high-impact errors,
- clearer uncertainty communication,
- reliable escalation behavior,
- and traceable decision history.
